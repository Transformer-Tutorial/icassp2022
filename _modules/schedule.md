---
title: Paper reading list and presenters
---

Session 1
: [Introduction and Motivation] (https://prismia.chat/shared/J2AE-A8GP) (May 24, 19:00 - 19:50)
  : Boqing Gong, Chen Sun

Session 2
: Recurrent Networks, Attention, Transformers (May 24, 20:00 - 21:30)
  : Boqing Gong, Chen Sun
: 1. [The Annotated Transformer](http://nlp.seas.harvard.edu/annotated-transformer/)
  1. [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
  1. [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)

Session 3
: Transformers for Vision and Long Sequences (May 24, 21:30 - 23:00)
  : Boqing Gong, Chen Sun
: 1. [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)
  1. [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030)
  1. [ViViT: A Video Vision Transformer](https://arxiv.org/abs/2103.15691)
  1. [Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context](https://arxiv.org/abs/1901.02860)
  1. [Big Bird: Transformers for Longer Sequences](https://arxiv.org/abs/2007.14062)
  1. [Long Range Arena: A Benchmark for Efficient Transformers](https://arxiv.org/abs/2011.04006)

Session 4
: Optimization for Transformers (May 25, 19:00 - 19:50)
  : Boqing Gong
: 1. [When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations](https://arxiv.org/abs/2106.01548)
  1. [Surrogate Gap Minimization Improves Sharpness-Aware Training](https://openreview.net/forum?id=edONMAnhLu-)

Session 5
: Transformers for Decision Making (May 25, 20:00 - 20:50)
  : Chen Sun
: 1. [Decision Transformer: Reinforcement Learning via Sequence Modeling](https://arxiv.org/abs/2106.01345)
  1. [Offline Reinforcement Learning as One Big Sequence Modeling Problem](https://trajectory-transformer.github.io/)
  1. [VectorNet: Encoding HD Maps and Agent Dynamics from Vectorized Representation](https://arxiv.org/abs/2005.04259)
  1. [Episodic Transformer for Vision-and-Language Navigation](https://arxiv.org/abs/2105.06453)

Session 6
: Multimodal Transformers (May 26, 19:00 - 20:50)
  : Boqing Gong, Chen Sun
: 1. [Attention Bottlenecks for Multimodal Fusion](https://arxiv.org/abs/2107.00135)
  1. [VideoBERT: A Joint Model for Video and Language Representation Learning](https://arxiv.org/abs/1904.01766)
  1. [VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text](https://arxiv.org/abs/2104.11178)
  1. [CLIP: Connecting Text and Images](https://openai.com/blog/clip/)
  1. [Learning Temporal Dynamics from Cycles in Narrated Video](https://arxiv.org/abs/2101.02337)

Session 7
: Model Interpretability (May 26, 21:00 - 21:50)
  : Chen Sun
: 1. [A Primer in BERTology: What we know about how BERT works](https://arxiv.org/abs/2002.12327)
  1. [BERT Rediscovers the Classical NLP Pipeline](https://arxiv.org/abs/1905.05950)
  1. [Do Vision-Language Pretrained Models Learn Primitive Concepts?](https://arxiv.org/abs/2203.17271)
  1. [Does Vision-and-Language Pretraining Improve Lexical Grounding?](https://arxiv.org/abs/2109.10246)

Session 8
: Advanced Topics, Recap (May 26, 22:00 - 22:50)
  : Boqing Gong
: 1. [MLP-Mixer: An all-MLP Architecture for Vision](https://arxiv.org/abs/2105.01601)
